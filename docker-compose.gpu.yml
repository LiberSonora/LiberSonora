services:
  streamlit:
    build:
      context: ./services/streamlit
      dockerfile: Dockerfile
    restart: always
    volumes:
      - ./services/streamlit:/app
      # mount whatever you want to process
      - /mnt/data:/mnt/data
    ports:
      - 8651:8501 # UI
      - 8652:8000 # API 
    environment:
      - WORKER_COUNT=1
  ollama:
    image: ollama/ollama:0.5.1
    environment:
      - HF_ENDPOINT=https://hf-mirror.com/
      - CUDA_VISIBLE_DEVICES=0
      - OLLAMA_DEBUG=1
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_ORIGINS="*"
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ./ollama:/root/.ollama
    #ports:
    #  - "11434:11434"
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  clear-voice:
    build:
      context: ./services/clear-voice
      dockerfile: Dockerfile
    restart: always
    volumes:
      # mount whatever you want to process
      - /mnt/data:/mnt/data
    ports:
      - 8502:8501 # UI
      - 8503:8000 # API
    environment:
      - WORKER_COUNT=${WORKER_COUNT:-1}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  funasr:
    build:
      context: ./services/funasr
      dockerfile: Dockerfile
    restart: always
    volumes:
      # mount whatever you want to process
      - /mnt/data:/mnt/data
      # 模型缓存
      - ./services/funasr/.cache/:/root/.cache/
    ports:
      - 8504:8501 # UI
      - 8505:8000 # API
    environment:
      - WORKER_COUNT=${WORKER_COUNT:-1}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]